{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ac6c8d1-fabd-46d1-8aff-4a5ac5c3ea87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "826b633a-9e21-4487-a30f-795aa84af843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We define a class, and name it PresidentialSpeechScraper.\n",
    "class PresidentialSpeechScraper:\n",
    "    # Initialize the class; then define the basic URL, create the president_id, president_name, and speech_data_list in order to transfer or receive data later.\n",
    "    def __init__(self, president_id, president_name):\n",
    "        self.base_url = \"https://millercenter.org/the-presidency/presidential-speeches\"\n",
    "        self.president_id = president_id\n",
    "        self.president_name = president_name\n",
    "        self.speech_data_list = []\n",
    "\n",
    "    # Now we begin to scrape links of speeches.\n",
    "    def scrape_speech_links(self):\n",
    "        # Create a complete link for each specific president, using '?' as a query string to combain self.base_url with target self.president_id. Besides, '=' here represents only the relationship between the key and the value, not the assignment operation, which means the string of this key-value pair is used to tell the server about a particular parameter and its value.\n",
    "        url = f\"{self.base_url}?field_president_target_id[{self.president_id}]={self.president_id}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = soup.find_all('div', class_='views-field-title')\n",
    "\n",
    "        for link in links:\n",
    "            title = link.find('a').text\n",
    "            speech_link = link.find('a')['href']\n",
    "            self.speech_data_list.append({'Title': title, 'Link': speech_link})\n",
    "    \n",
    "    # Process text\n",
    "    def save_speech_to_text_file(self, title, speech):\n",
    "        filename = f\"{self.president_name}_{title.replace(' ', '_')}.txt\"\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(speech)\n",
    "        print(f\"Speech text saved to {filename}\")\n",
    "    \n",
    "    # Then we start to scrape more details in every speeches.\n",
    "    def scrape_speech_details(self):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        for speech_data in self.speech_data_list:\n",
    "            link = speech_data['Link']\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            title = soup.find('h1').text.strip()\n",
    "            president = soup.find('p', class_='president-name').text.strip()\n",
    "            date = soup.find('p', class_='episode-date').text.strip()\n",
    "            summary = soup.find('div', class_='about-sidebar--intro').p.text.strip()\n",
    "            speech_elements = soup.find_all('div', class_='transcript-inner')\n",
    "            # Connect all the texts in <div> and delete the possible 'Transcript' in texts/\n",
    "            speech = '\\n'.join([element.text.strip().replace(\"Transcript\\n\", \"\") for element in speech_elements])\n",
    "            \n",
    "            self.save_speech_to_text_file(title, speech)\n",
    "            \n",
    "            # Now we can add the information extracted from the speech details to the dictionary separately.\n",
    "            doc = nlp(speech)\n",
    "            tokens = [token.text for token in doc]\n",
    "            lemmas = [token.lemma_ for token in doc]\n",
    "            pos_tags = [token.pos_ for token in doc]\n",
    "            \n",
    "            speech_data.update({\n",
    "                'Title': title,\n",
    "                'President': president,\n",
    "                'Date': date,\n",
    "                'Summary': summary,\n",
    "                'Speech': speech,\n",
    "                'Tokens': tokens,\n",
    "                'Lemmas': lemmas,\n",
    "                'Parts-of-speech': pos_tags\n",
    "            })\n",
    "\n",
    "    # Save the data above to csv. files.\n",
    "    def save_to_csv(self):\n",
    "        filename= f\"{self.president_name}_presidential_speeches.csv\"\n",
    "        df = pd.DataFrame(self.speech_data_list)\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"Speech data saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd1262a-dc65-4e86-a5aa-f4d575b8e824",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech text saved to Biden_October_20,_2023:_Remarks_on_the_US_Response_in_Support_of_Israel_and_Ukraine.txt\n",
      "Speech text saved to Biden_February_21,_2023:_Remarks_on_the_One-Year_Anniversary_of_the_Ukraine_War.txt\n",
      "Speech text saved to Biden_February_7,_2023:_State_of_the_Union_Address.txt\n",
      "Speech text saved to Biden_September_21,_2022:_Speech_before_the_77th_Session_of_the_United_Nations_General_Assembly.txt\n",
      "Speech text saved to Biden_September_1,_2022:_Remarks_on_the_Continued_Battle_for_the_Soul_of_the_Nation.txt\n",
      "Speech text saved to Biden_May_24,_2022:_Remarks_on_School_Shooting_in_Uvalde,_Texas.txt\n",
      "Speech text saved to Biden_March_26,_2022:_Remarks_in_Support_of_the_People_of_Ukraine.txt\n",
      "Speech text saved to Biden_March_1,_2022:_State_of_the_Union_Address.txt\n",
      "Speech text saved to Biden_February_24,_2022:_Remarks_on_the_Russian_Invasion_of_Ukraine.txt\n",
      "Speech text saved to Biden_January_6,_2022:_Remarks_on_the_Anniversary_of_the_January_6th_Assault_on_the_US_Capitol.txt\n",
      "Speech text saved to Biden_November_15,_2021:_Signing_the_Infrastructure_Investment_and_Jobs_Act.txt\n",
      "Speech text saved to Biden_September_9,_2021:_Remarks_on_Fighting_the_COVID-‚Å†19_Pandemic.txt\n",
      "Speech text saved to Biden_August_26,_2021:_Statement_on_Terror_Attacks_in_Afghanistan.txt\n",
      "Speech text saved to Biden_August_16,_2021:_Remarks_on_Situation_in_Afghanistan.txt\n",
      "Speech text saved to Biden_July_8,_2021:_Speech_on_the_Drawdown_of_US_Forces_in_Afghanistan.txt\n",
      "Speech text saved to Biden_June_1,_2021:_Remarks_Commemorating_the_100th_Anniversary_of_the_Tulsa_Race_Massacre.txt\n",
      "Speech text saved to Biden_April_28,_2021:_Address_to_Joint_Session_of_Congress.txt\n",
      "Speech text saved to Biden_March_31,_2021:_Announcing_the_American_Jobs_Plan.txt\n",
      "Speech text saved to Biden_March_25,_2021:_First_Press_Conference.txt\n",
      "Speech text saved to Biden_March_11,_2021:_Remarks_on_the_Anniversary_of_the_Coronavirus_Shutdown.txt\n",
      "Speech text saved to Biden_January_20,_2021:_Inaugural_Address.txt\n",
      "Speech data saved to Biden_presidential_speeches.csv\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of Biden for the class of PresidentialSpeechScraper.\n",
    "Biden_scraper = PresidentialSpeechScraper(president_id=30721, president_name ='Biden')\n",
    "\n",
    "Biden_scraper.scrape_speech_links()\n",
    "Biden_scraper.scrape_speech_details()\n",
    "\n",
    "Biden_scraper.save_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089b549-a21f-4d1c-85bd-7076c59bc287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
